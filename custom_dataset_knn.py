# -*- coding: utf-8 -*-
"""Custom Dataset KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QyqH4U0K0mK8Pbd-rxq5QVAWfVUIl2QG
"""

# Import required libraries
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Step 1: Load dataset
data = load_iris()         # Load the Iris dataset
X = data.data              # Features (inputs)
y = data.target            # Labels (outputs)

# Step 2: Split data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=40
)

# Step 3: Initialize and train the KNN classifier
knn = KNeighborsClassifier(n_neighbors=50)
knn.fit(X_train, y_train)

# Step 4: Make predictions
y_pred = knn.predict(X_test)

# Step 5: Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Model accuracy: {accuracy:.2f}")

# Step 6: Evaluate accuracy for both
y_train_pred = knn.predict(X_train) # Predict on training data
y_test_pred = knn.predict(X_test)   # Predict on testing data

train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

# Step 7: Print the results
print("Training Accuracy:", train_accuracy)
print("Testing Accuracy:", test_accuracy)

"""# Custom DATA SET implementation

"""



"""# Task
Implement a KNN model on the dataset located at "/content/drive/MyDrive/AI Lab/student_knn_dataset.csv" following a step-by-step process including data loading, exploration, preprocessing, splitting, training, and evaluation.

## Load the student knn dataset

### Subtask:
Load the data from "/content/drive/MyDrive/AI Lab/student_knn_dataset.csv" into a pandas DataFrame.

**Reasoning**:
Import pandas and load the CSV file into a DataFrame, then display the first few rows.
"""

import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/AI Lab/student_knn_dataset.csv")
display(df.head())

"""## Explore and preprocess the data

### Subtask:
Inspect the dataset to understand its structure, identify features and the target variable, check for missing values, and determine if any data type conversions or feature scaling are needed for the KNN model. Handle missing values and prepare the data for the model.

**Reasoning**:
Display information about the DataFrame and check for missing values to understand the data structure and identify potential issues.
"""

display(df.info())
display(df.isnull().sum())

"""**Reasoning**:
Display descriptive statistics for numerical columns to understand the data distribution and identify features and the target variable.


"""

display(df.describe())

"""**Reasoning**:
Based on the dataset information, the 'Name' and 'Roll No' columns are identifiers and not relevant features for the KNN model. The 'Target' column is the categorical target variable, which needs to be encoded. The 'Math Marks', 'Physics Marks', and 'Attendance' columns are numerical features. The target variable 'Target' needs to be converted to a numerical format. Then, the features and target variable will be separated.


"""

from sklearn.preprocessing import LabelEncoder

# Identify features (X) and target variable (y)
features = ['Math Marks', 'Physics Marks', 'Attendance']
target = 'Target'

X = df[features]
y = df[target]

# Convert the target variable to numerical format
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Display the first few encoded target values
display(y_encoded[:5])

"""**Reasoning**:
The features are already numerical based on the previous steps. KNN is sensitive to the scale of features, so feature scaling is necessary. Standardize the numerical features using StandardScaler.


"""

from sklearn.preprocessing import StandardScaler

# Apply feature scaling to the numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Display the first few rows of the scaled features
display(X_scaled[:5])

"""## Split data

### Subtask:
Split the preprocessed data into training and testing sets.

**Reasoning**:
Split the scaled features and encoded target variable into training and testing sets using train_test_split.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_encoded, test_size=0.2, random_state=42
)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Adapt and train the knn model

### Subtask:
Adapt the existing KNN code to use the preprocessed student KNN data. Train the KNN classifier on the training data.

**Reasoning**:
Import the KNeighborsClassifier, instantiate it, and train the model on the training data.
"""

from sklearn.neighbors import KNeighborsClassifier

# Instantiate a KNeighborsClassifier with n_neighbors = 5
knn = KNeighborsClassifier(n_neighbors=5)

# Train the KNN model using the training data
knn.fit(X_train, y_train)

"""## Evaluate the model

### Subtask:
Evaluate the trained model's performance on the testing data using appropriate metrics for classification tasks.

**Reasoning**:
Make predictions on the test set and calculate the accuracy.
"""

from sklearn.metrics import accuracy_score

y_pred = knn.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Model accuracy on test data: {accuracy:.2f}")

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 50 entries and no missing values.
*   The target variable 'Target' was successfully encoded into numerical values.
*   Numerical features ('Math Marks', 'Physics Marks', 'Attendance') were scaled using `StandardScaler`.
*   The data was split into training (40 samples) and testing (10 samples) sets, with a test size of 20%.
*   A `KNeighborsClassifier` with 5 neighbors was instantiated and trained on the training data.
*   The trained KNN model achieved an accuracy of 0.90 on the test data.

### Insights or Next Steps

*   An accuracy of 90% suggests the model performs well on this dataset. Further evaluation with other metrics like precision, recall, and F1-score could provide a more comprehensive understanding of the model's performance, especially if the classes are imbalanced.
*   Experimenting with different values for `n_neighbors` could potentially improve the model's performance.

"""